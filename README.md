# üîç Why we use Explainable AI (XAI) in CNN models

Explainable AI (XAI) is used to understand how a deep learning model makes decisions.
In image classification tasks, CNN models often work like a black box ‚Äî they give predictions without showing the reason behind them.

Using techniques like Grad-CAM, we can visualize the important regions of an image that influenced the model‚Äôs prediction.
This helps us verify whether the model is focusing on the correct object instead of background noise.

## XAI is useful for:

- Improving model trust and transparency

- Debugging wrong predictions

- Understanding CNN behavior

- Making models more reliable in real-world applications
